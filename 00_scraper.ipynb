{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawler\n",
    "> This repository aims to explore the catalog available at wine.com.br, do some exploratory analysis in it and\n",
    "create initially a toy recommendation engine / wine classifier and pricing tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from fire import Fire\n",
    "from nbdev.showdoc import *\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from functools import partial\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG = \"//article\"\n",
    "NEXT = \"/html/body/div[6]/div/div[2]/div[2]/div/div[4]/div\"\n",
    "prefix = \"https://wine.com.br\"\n",
    "#url_short = \"https://www.wine.com.br/browse.ep?cID=100851&exibirEsgotados=true&listagem=horizontal&sorter=featuredProducts-desc&filters=cVINHOS\"\n",
    "url_short = \"https://www.wine.com.br/browse.ep?cID=100851&exibirEsgotados=false&pn=1&listagem=horizontal&sorter=featuredProducts-desc&filters=cVINHOS\" \n",
    "url_next = \"https://www.wine.com.br/browse.ep?cID=100851&exibirEsgotados=false&pn={page}&listagem=horizontal&sorter=featuredProducts-desc&filters=cVINHOS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatalogClassic(scrapy.Spider):\n",
    "    name = \"catalog_classic\"\n",
    "    #url = url_short\n",
    "    i=1\n",
    "\n",
    "    def start_requests(self):\n",
    "        yield scrapy.Request(url=url_short, callback=self.parse_page)\n",
    "\n",
    "    def parse_page(self, response, count=i):\n",
    "        wine_list = response.xpath(CATALOG)\n",
    "        for block in wine_list:\n",
    "            yield {\n",
    "                \"wine\": block.css('div > a::attr(\"title\")').get(),\n",
    "                \"link\": prefix + block.css('div > a::attr(\"href\")').get(),\n",
    "                \"país\": block.xpath('div[2]/div[1]/div/span').get()\n",
    "            }\n",
    "        #/html/body/div[5]/div/div[2]/div[2]/div/div[3]/ul/li[1]/article/div[2]/div[2]/div[1]/div/span\n",
    "        #next_page = response.xpath(f\"//a[./text()='Próxima >>']/@href\").get()\n",
    "        count +=1\n",
    "        next_page = url_next.format(page=count)\n",
    "        parse_next = partial(self.parse_page, count=count)\n",
    "        if count <= 431:\n",
    "            yield response.follow(next_page, parse_next)\n",
    "        \n",
    "\n",
    "    # Second parsing method\n",
    "    def parse_pages(self, response):\n",
    "        crs_title = response.xpath('//h1[contains(@class,\"title\")]/text()')\n",
    "        crs_title_ext = crs_title.extract_first().strip()\n",
    "        ch_titles = response.css(\"p.course__description::text\")\n",
    "        ch_titles_ext = [t.strip() for t in ch_titles.extract()]\n",
    "        dc_dict[crs_title_ext] = ch_titles_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CatalogFaster(scrapy.Spider):\n",
    "    name = \"catalog\"\n",
    "    start_urls = [url_short] + [url_next.format(page=i) for i in range(2, 85)]\n",
    "    \n",
    "\n",
    "    def parse(self, response):\n",
    "        wine_list = response.xpath(CATALOG)\n",
    "        for block in wine_list:\n",
    "            tag = soup(block.get(), 'lxml')\n",
    "            key = []\n",
    "            val = []\n",
    "            \n",
    "            title = tag.find('h2')\n",
    "            \n",
    "            if title:\n",
    "                key.append(\"Nome\")\n",
    "                val.append(title.string)\n",
    "\n",
    "            precos = tag.find_all(class_='Price-raw')        \n",
    "\n",
    "            if len(precos) >= 2:\n",
    "                precos = sorted(list(set([float(p.string) for p in precos])))\n",
    "                key.append('Preço_Sócio')\n",
    "                val.append(precos[0])\n",
    "                key.append('Preço_Normal')\n",
    "                val.append(precos[1])\n",
    "            #elif len(precos) == 2:\n",
    "            #    precos = sorted([float(p.string) for p in precos])\n",
    "#                 key.append('Preço_Sócio')\n",
    "#                 val.append(precos[0])\n",
    "#                 key.append('Preço_Normal')\n",
    "#                 val.append(precos[1])\n",
    "                \n",
    "            \n",
    "                \n",
    "            avaliação = tag.find(\"evaluation-tag\")\n",
    "            \n",
    "           # print(f\"Avaliação: {avaliação.attrs}\")\n",
    "            if avaliação:\n",
    "                key.append(\"Pontuação\")\n",
    "                val.append(float(avaliação[':evaluation']))\n",
    "                \n",
    "\n",
    "            rating = tag.find('a', class_='Rating-count', string=True)\n",
    "            \n",
    "            if rating:\n",
    "                key.append(\"Avaliações\")\n",
    "                rating = rating.string.replace(\"(\", \"\")\n",
    "                rating = rating.replace(\")\", \"\")\n",
    "                val.append(rating)\n",
    "        \n",
    "            yield dict(zip(key, val))\n",
    "    # Second parsing method\n",
    "    def parse_pages(self, response):\n",
    "        crs_title = response.xpath('//h1[contains(@class,\"title\")]/text()')\n",
    "        crs_title_ext = crs_title.extract_first().strip()\n",
    "        ch_titles = response.css(\"p.course__description::text\")\n",
    "        ch_titles_ext = [t.strip() for t in ch_titles.extract()]\n",
    "        dc_dict[crs_title_ext] = ch_titles_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl():\n",
    "    # Run the Spider\n",
    "    process = CrawlerProcess()\n",
    "    process.crawl(CatalogFaster)\n",
    "    process.start()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Fire(crawl)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "wino_conda",
   "language": "python",
   "name": "wino_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
