{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawler\n",
    "> This repository aims to explore the catalog available at wine.com.br, do some exploratory analysis in it and\n",
    "create initially a toy recommendation engine / wine classifier and pricing tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from fire import Fire\n",
    "from nbdev.showdoc import *\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from functools import partial\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG = \"//article\"\n",
    "NEXT = \"/html/body/div[6]/div/div[2]/div[2]/div/div[4]/div\"\n",
    "prefix = \"https://wine.com.br\"\n",
    "COUNT = 434\n",
    "#url_short = \"https://www.wine.com.br/browse.ep?cID=100851&exibirEsgotados=true&listagem=horizontal&sorter=featuredProducts-desc&filters=cVINHOS\"\n",
    "url_short = \"https://www.wine.com.br/browse.ep?cID=100851&exibirEsgotados=true&pn=1&listagem=horizontal&sorter=featuredProducts-desc&filters=cVINHOS\" \n",
    "url_next = \"https://www.wine.com.br/browse.ep?cID=100851&exibirEsgotados=true&pn={page}&listagem=horizontal&sorter=featuredProducts-desc&filters=cVINHOS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIPOS = {'Branco', 'Espumante', 'Frisante', 'Licoroso', 'Rosé', 'Tinto'}\n",
    "PAISES = {'África do Sul', 'Alemanha', 'Argentina', 'Austrália', 'Brasil', 'Chile'\n",
    "          'China', 'Espanha', 'Estados Unidos', 'França', 'Hungria', 'Itália', 'Líbano'\n",
    "          'Nova Zelândia', 'Portugal', 'Uruguai', 'Grécia', 'Marrocos'}\n",
    "\n",
    "KEYS = {'Tipo', 'Uvas', 'Origem', 'Vinícola', 'Teor Alcoólico', 'Amadurecimento', 'Safra','Classificação', 'Visual', \n",
    "        'Olfativo', 'Gustativo', 'Temperatura de serviço', 'Potencial de guarda', 'Decantação', 'Harmonização'}\n",
    "\n",
    "OTHER = {'Vinícola', 'Teor Alcoólico', 'Amadurecimento', 'Safra','Classificação', 'Visual', \n",
    "        'Olfativo', 'Gustativo', 'Temperatura de serviço', 'Potencial de guarda', 'Decantação', 'Harmonização'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatalogClassic(scrapy.Spider):\n",
    "    name = \"catalog_classic\"\n",
    "    #url = url_short\n",
    "    i=1\n",
    "\n",
    "    def start_requests(self):\n",
    "        yield scrapy.Request(url=url_short, callback=self.parse_page)\n",
    "\n",
    "    def parse_page(self, response, count=i):\n",
    "        \n",
    "        wine_list = response.xpath(CATALOG)\n",
    "        for block in wine_list:\n",
    "            tag = soup(block.get(), 'lxml')\n",
    "            key = []\n",
    "            val = []\n",
    "\n",
    "            link = prefix + block.css('div > a::attr(\"href\")').get()\n",
    "\n",
    "            key += [\"link\"]\n",
    "            val += [link]\n",
    "\n",
    "            title = tag.find('h2')\n",
    "            \n",
    "            key.append(\"Nome\")\n",
    "\n",
    "            if title:\n",
    "                val.append(title.string)\n",
    "            else:\n",
    "                val.append(None)\n",
    "                \n",
    "            key.append(\"País\")\n",
    "            \n",
    "            country = tag.find('div', class_=\"Country\")\n",
    "            \n",
    "            if country:\n",
    "                val.append(country.string)\n",
    "            else:\n",
    "                val.append(None)\n",
    "\n",
    "            precos = tag.find_all(class_='Price-raw')\n",
    "            \n",
    "            key.extend(['Preço_Sócio', 'Preço_Normal'])\n",
    "\n",
    "            if len(precos) >= 2:\n",
    "                precos = sorted(list(set([float(p.string) for p in precos])))\n",
    "                val.extend(precos[0:2])\n",
    "            else:\n",
    "                val.extend([None]*2)\n",
    "\n",
    "\n",
    "            avaliação = tag.find(\"evaluation-tag\")\n",
    "                       \n",
    "            key.append(\"Pontuação\")\n",
    "\n",
    "            if avaliação:\n",
    "                val.append(float(avaliação[':evaluation']))\n",
    "            else:\n",
    "                val.append(None)\n",
    "                       \n",
    "                       \n",
    "            key.append(\"Avaliações\")\n",
    " \n",
    "            rating = tag.find('a', class_='Rating-count', string=True)\n",
    "\n",
    "            if rating:\n",
    "                rating = rating.string.replace(\"(\", \"\")\n",
    "                rating = rating.replace(\")\", \"\")\n",
    "                val.append(rating)\n",
    "                \n",
    "            parse_vinho = partial(self.ficha_tecnica, dict_=dict(zip(key, val)))\n",
    "                \n",
    "            yield response.follow(link, parse_vinho)\n",
    "                \n",
    "\n",
    "        count +=1\n",
    "        next_page = url_next.format(page=count)\n",
    "        parse_next = partial(self.parse_page, count=count)\n",
    "        if count <= COUNT:\n",
    "            yield response.follow(next_page, parse_next)\n",
    "            \n",
    "    # Second parsing method\n",
    "    def ficha_tecnica(self, response, dict_):\n",
    "        page = response.xpath('/html').get()\n",
    "        tag = soup(page, 'lxml')\n",
    "        #key = []\n",
    "        #val = []\n",
    "        \n",
    "        \n",
    "        v = tag.find(class_=\"somelier__description\")\n",
    "        dict_['somelier'] = v.string.strip() if v else None\n",
    "        \n",
    "        rights = tag.find_all('div', class_=\"Right\")\n",
    "        \n",
    "#         keys = []\n",
    "#         vals = []\n",
    "#         for t in rights:\n",
    "#             keys.append(t.attrs.get('dt'))\n",
    "#             vals.append(t.attrs.get('dd'))\n",
    "        \n",
    "        keys = [t.string for t in tag.find_all('dt')]\n",
    "        vals = [t.string for t in tag.find_all('dd')]\n",
    "        \n",
    "        dict_ = {**dict_, **{k:None for k in KEYS}}\n",
    "        \n",
    "        for k,v in zip(keys, vals):\n",
    "            if k in TIPOS:\n",
    "                dict_['Tipo'] = k\n",
    "                dict_['Uvas'] = v\n",
    "            elif k in PAISES:\n",
    "                dict_['Origem'] = f'{k}-{v}'\n",
    "            elif k in OTHER:\n",
    "                dict_[k] = v                \n",
    "        \n",
    "        yield dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# class CatalogFaster(scrapy.Spider):\n",
    "#     name = \"catalog\"\n",
    "#     start_urls = [url_short] + [url_next.format(page=i) for i in range(2, 85)]\n",
    "    \n",
    "\n",
    "#     def parse(self, response):\n",
    "#         wine_list = response.xpath(CATALOG)\n",
    "#         for block in wine_list:\n",
    "#             tag = soup(block.get(), 'lxml')\n",
    "#             key = []\n",
    "#             val = []\n",
    "            \n",
    "#             key += [\"link\"]\n",
    "#             val += [prefix + block.css('div > a::attr(\"href\")').get()]\n",
    "            \n",
    "#             title = tag.find('h2')\n",
    "            \n",
    "#             if title:\n",
    "#                 key.append(\"Nome\")\n",
    "#                 val.append(title.string)\n",
    "\n",
    "#             precos = tag.find_all(class_='Price-raw')        \n",
    "\n",
    "#             if len(precos) >= 2:\n",
    "#                 precos = sorted(list(set([float(p.string) for p in precos])))\n",
    "#                 key.append('Preço_Sócio')\n",
    "#                 val.append(precos[0])\n",
    "#                 key.append('Preço_Normal')\n",
    "#                 val.append(precos[1])\n",
    "            \n",
    "                \n",
    "#             avaliação = tag.find(\"evaluation-tag\")\n",
    "            \n",
    "#            # print(f\"Avaliação: {avaliação.attrs}\")\n",
    "#             if avaliação:\n",
    "#                 key.append(\"Pontuação\")\n",
    "#                 val.append(float(avaliação[':evaluation']))\n",
    "                \n",
    "\n",
    "#             rating = tag.find('a', class_='Rating-count', string=True)\n",
    "            \n",
    "#             if rating:\n",
    "#                 key.append(\"Avaliações\")\n",
    "#                 rating = rating.string.replace(\"(\", \"\")\n",
    "#                 rating = rating.replace(\")\", \"\")\n",
    "#                 val.append(rating)\n",
    "        \n",
    "#             yield dict(zip(key, val))\n",
    "            \n",
    "#     # Second parsing method\n",
    "#     def ficha_tecnica(self, key, val, tag):\n",
    "#         tag = soup(tag, 'lxml')\n",
    "#         key = []\n",
    "#         val = []\n",
    "        \n",
    "#         v = tag.find(class_=\"somelier__description\")\n",
    "#         key.append('somelier')\n",
    "#         val.append(v.string.strip() if v else '')\n",
    "        \n",
    "#         keys = [t.string for t in tag.find_all('dt')]\n",
    "#         vals = [t.string for t in tag.find_all('dd')]\n",
    "        \n",
    "               \n",
    "#         for k,v in zip(keys, vals):\n",
    "#             if k in TIPOS:\n",
    "#                 key.append('tipo')\n",
    "#                 val.append(k)\n",
    "#             elif k in PAISES:\n",
    "#                 key.append('origem')\n",
    "#                 val.append(f'{k}-{v}')\n",
    "#             else:\n",
    "#                 key.append(k)\n",
    "#                 val.append(v)\n",
    "                \n",
    "        \n",
    "#         return dict(zip(key, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl():\n",
    "    # Run the Spider\n",
    "    process = CrawlerProcess()\n",
    "    process.crawl(CatalogClassic)\n",
    "    process.start()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Fire(crawl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"\"\"<div class=\"Right\">\n",
    "<dt>Rosé</dt>\n",
    "<dd>Grenache (70%), Syrah (5%), Cinsault (25%)</dd>\n",
    "</div>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = soup(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dt>Rosé</dt>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "wino_conda",
   "language": "python",
   "name": "wino_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
